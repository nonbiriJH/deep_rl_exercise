{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Junhong Chen\\Documents\\GitHub\\deep_rl_exercise\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Junhong Chen\\Documents\\GitHub\\deep_rl_exercise\\.venv\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "# !pip install gym-super-mario-bros==7.3.0\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Junhong Chen\\Documents\\GitHub\\deep_rl_exercise\\.venv\\lib\\site-packages\\gym\\envs\\registration.py:505: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3` with the environment ID `SuperMarioBros-1-1-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x151cfaedff0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Super Mario environment\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
    "plt.imshow(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        #bilinear resize\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x151d1c05a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
    "plt.imshow(next_state[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCTS (s,net,env):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.net = self.net.to(device=\"cuda\")\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = exploration_rate_decay\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = save_every  # no. of experiences between saving Mario Net\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    Given a state, choose an epsilon-greedy action and update value of step.\n",
    "\n",
    "    Inputs:\n",
    "    state(LazyFrame): A single observation of the current state, dimension is (state_dim)\n",
    "    Outputs:\n",
    "    action_idx (int): An integer representing which action Mario will perform\n",
    "    \"\"\"\n",
    "        # EXPLORE\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # EXPLOIT\n",
    "        else:\n",
    "            state = state.__array__() #from lazy frame to array\n",
    "            if self.use_cuda:\n",
    "                state = torch.tensor(state).cuda()\n",
    "            else:\n",
    "                state = torch.tensor(state)\n",
    "            state = state.unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent's memory\n",
    "class Mario(Mario):  # subclassing for continuity\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Each time Mario performs an action, he stores the experience to his memory. \n",
    "        His experience includes the current state, action performed, reward from the action, the next state, and whether the game is done.\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (LazyFrame),\n",
    "        next_state (LazyFrame),\n",
    "        action (int),\n",
    "        reward (float),\n",
    "        done(bool))\n",
    "        \"\"\"\n",
    "        state = state.__array__()\n",
    "        next_state = next_state.__array__()\n",
    "\n",
    "        if self.use_cuda:\n",
    "            state = torch.tensor(state).cuda()\n",
    "            next_state = torch.tensor(next_state).cuda()\n",
    "            action = torch.tensor([action]).cuda()\n",
    "            reward = torch.tensor([reward]).cuda()\n",
    "            done = torch.tensor([done]).cuda()\n",
    "        else:\n",
    "            state = torch.tensor(state)\n",
    "            next_state = torch.tensor(next_state)\n",
    "            action = torch.tensor([action])\n",
    "            reward = torch.tensor([reward])\n",
    "            done = torch.tensor([done])\n",
    "\n",
    "        self.memory.append((state, next_state, action, reward, done,))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        # *batch: unpact batch to individual (s,s',a,r,d)\n",
    "        # zip(): create an iteracble on unpacked batch\n",
    "        # map(): apply torch.stack in each iterable\n",
    "        # torch.stack: Concatenates a sequence of tensors along a new dimension.\n",
    "        state, next_state, action, reward, done = map(torch.stack, zip(*batch))\n",
    "        # squeeze(): dimension 1 is removed\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DDQN: two ConvNets - online & target, that independently approximate the optimal action-value function.\n",
    "#Both share the same nn struc but seperate (w,b)\n",
    "#target does not back propagate to update (w,b). Periodically sync with online\n",
    "class MarioNet(nn.Module):\n",
    "    \"\"\"mini cnn structure\n",
    "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )\n",
    "\n",
    "        self.target = copy.deepcopy(self.online)\n",
    "\n",
    "        # Q_target parameters are frozen.\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        \n",
    "        current_state_Q = self.net(state, model=\"online\")#Q for (batch,action_space)\n",
    "        current_Q = current_state_Q[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        \n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad() #don’t need to backpropagate on target (w,b)\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        #use online model to find a'\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        #use target model to find q(s',a')\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=learn_rate)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss() #mean reduction\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target) #loss between current and target TD\n",
    "        self.optimizer.zero_grad() #reset grad on each weight to 0, otherwise accumulate on batch\n",
    "        loss.backward() #compute loss grad wrt weights\n",
    "        #theta <- theta + lr * Delta(TD_target-q(s,a))\n",
    "        self.optimizer.step() #adjust weights by grad and learning rate\n",
    "        return loss.item() #report loss\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        #periodically copy online weights to target model\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoint\n",
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate), #exploration rate changing during training\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
    "    def load(self,load_path):\n",
    "        try:\n",
    "            self.net.load_state_dict(torch.load(load_path)['model'])\n",
    "            self.exploration_rate = torch.load(load_path)['exploration_rate']\n",
    "        except:\n",
    "            print(\n",
    "                f\"no weights are loaded as either {load_path} cannot be found or incompatible to current model.\")\n",
    "        else:\n",
    "            print(f\"weights are loaded successfuly! exploration_rate is {self.exploration_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate)\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory in batch\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate in batch\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target in batch\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_rewards\", \"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\"]:\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"))\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n",
      "no weights are loaded as either /Users/junhongchen/Documents/GitHub/deep_rl_exercise/pytorch_basic/mario/checkpoints/2022-03-12T00-31-11/mario_net_4.chkpt cannot be found or incompatible to current model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Junhong Chen\\AppData\\Local\\Temp\\ipykernel_23596\\3067730520.py:29: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  done = torch.tensor([done]).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Step 616 - Epsilon 0.9998460118381219 - Mean Reward 665.0 - Mean Length 616.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 4.133 - Time 2022-05-07T09:00:23\n",
      "Episode 20 - Step 4567 - Epsilon 0.9988589014058243 - Mean Reward 620.714 - Mean Length 217.476 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 32.141 - Time 2022-05-07T09:00:55\n",
      "Episode 40 - Step 7225 - Epsilon 0.9981953800621871 - Mean Reward 605.854 - Mean Length 176.22 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 19.46 - Time 2022-05-07T09:01:15\n",
      "Episode 60 - Step 10612 - Epsilon 0.9973505157632944 - Mean Reward 601.82 - Mean Length 173.967 - Mean Loss 0.092 - Mean Q Value 0.136 - Time Delta 26.916 - Time 2022-05-07T09:01:42\n",
      "Episode 80 - Step 14661 - Epsilon 0.9963414583727723 - Mean Reward 619.852 - Mean Length 181.0 - Mean Loss 0.239 - Mean Q Value 0.979 - Time Delta 42.912 - Time 2022-05-07T09:02:25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir,exploration_rate_decay=0.99999975,save_every=2e5,learn_rate=0.00025)\n",
    "mario.load(\"/Users/junhongchen/Documents/GitHub/deep_rl_exercise/pytorch_basic/mario/checkpoints/2022-03-12T00-31-11/mario_net_4.chkpt\")\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 100\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Junhong Chen\\Documents\\GitHub\\deep_rl_exercise\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_filter, n_padding):\n",
    "        super().__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_filter, out_channels = n_filter, kernel_size = 3,padding=n_padding),\n",
    "            nn.BatchNorm2d(n_filter),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=n_filter, out_channels = n_filter, kernel_size = 3,padding=n_padding),\n",
    "            nn.BatchNorm2d(n_filter),\n",
    "          )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.ReLU()(self.module(inputs) + inputs)\n",
    "\n",
    "class MuNet(nn.Module):\n",
    "\n",
    "    def __init__(self, policy_dim, is_reference):\n",
    "        super().__init__()\n",
    "        self.policy_dim = policy_dim\n",
    "        self.is_reference = is_reference\n",
    "        if is_reference:\n",
    "          self.body_feature = 256\n",
    "        else:\n",
    "          self.body_feature = 256 + self.policy_dim\n",
    "        \n",
    "        #INPUT NET\n",
    "        #Representation - input observation 96x96x(32x(3+1))\n",
    "        self.rep = nn.Sequential(\n",
    "          nn.Conv2d(128,128,3,stride=2, padding=1), #48x48x128\n",
    "          ResNet(128,1),\n",
    "          ResNet(128,1),\n",
    "          nn.Conv2d(128,256,3,stride=2, padding=1), #24x24x256\n",
    "          ResNet(256,1),\n",
    "          ResNet(256,1),\n",
    "          ResNet(256,1),\n",
    "          nn.AvgPool2d(2), #12x12x256\n",
    "          ResNet(256,1),\n",
    "          ResNet(256,1),\n",
    "          ResNet(256,1),\n",
    "          nn.AvgPool2d(2),#6x6x256 hidden state out\n",
    "        )\n",
    "        #Dynamic - input hidden state 6x6x256 and action 6x6xpolicy_dim\n",
    "\n",
    "        #OUTPUT NET\n",
    "        self.pol = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=self.body_feature, out_channels = 1, kernel_size = 1), #2 conv layer\n",
    "          nn.BatchNorm2d(1),\n",
    "          nn.ReLU(),\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(in_features = 6*6,out_features=self.policy_dim),\n",
    "        )\n",
    "\n",
    "        self.val = nn.Sequential(\n",
    "          \n",
    "          nn.Conv2d(in_channels=self.body_feature, out_channels = 1, kernel_size = 1), #1 conv layer\n",
    "          nn.BatchNorm2d(1),\n",
    "          nn.ReLU(),\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(in_features = 6*6,out_features=6),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(in_features =6,out_features=1),\n",
    "          #tanh\n",
    "        )\n",
    "\n",
    "        self.reward = self.val\n",
    "\n",
    "        #BODY NET\n",
    "        self.body = nn.Sequential()\n",
    "        for _ in range(16):\n",
    "          self.body = nn.Sequential(\n",
    "            self.body,\n",
    "            ResNet(self.body_feature,1))\n",
    "\n",
    "    def forward(self, input):\n",
    "      if self.is_reference:\n",
    "        net = nn.Sequential(self.rep,self.body)\n",
    "        out = net(input)\n",
    "      return self.pol(out),self.val(out),self.reward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 48, 48]         147,584\n",
      "            Conv2d-2          [-1, 128, 48, 48]         147,584\n",
      "       BatchNorm2d-3          [-1, 128, 48, 48]             256\n",
      "              ReLU-4          [-1, 128, 48, 48]               0\n",
      "            Conv2d-5          [-1, 128, 48, 48]         147,584\n",
      "       BatchNorm2d-6          [-1, 128, 48, 48]             256\n",
      "            ResNet-7          [-1, 128, 48, 48]               0\n",
      "            Conv2d-8          [-1, 128, 48, 48]         147,584\n",
      "       BatchNorm2d-9          [-1, 128, 48, 48]             256\n",
      "             ReLU-10          [-1, 128, 48, 48]               0\n",
      "           Conv2d-11          [-1, 128, 48, 48]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 48, 48]             256\n",
      "           ResNet-13          [-1, 128, 48, 48]               0\n",
      "           Conv2d-14          [-1, 256, 24, 24]         295,168\n",
      "           Conv2d-15          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-16          [-1, 256, 24, 24]             512\n",
      "             ReLU-17          [-1, 256, 24, 24]               0\n",
      "           Conv2d-18          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 24, 24]             512\n",
      "           ResNet-20          [-1, 256, 24, 24]               0\n",
      "           Conv2d-21          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 24, 24]             512\n",
      "             ReLU-23          [-1, 256, 24, 24]               0\n",
      "           Conv2d-24          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-25          [-1, 256, 24, 24]             512\n",
      "           ResNet-26          [-1, 256, 24, 24]               0\n",
      "           Conv2d-27          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-28          [-1, 256, 24, 24]             512\n",
      "             ReLU-29          [-1, 256, 24, 24]               0\n",
      "           Conv2d-30          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-31          [-1, 256, 24, 24]             512\n",
      "           ResNet-32          [-1, 256, 24, 24]               0\n",
      "        AvgPool2d-33          [-1, 256, 12, 12]               0\n",
      "           Conv2d-34          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-35          [-1, 256, 12, 12]             512\n",
      "             ReLU-36          [-1, 256, 12, 12]               0\n",
      "           Conv2d-37          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-38          [-1, 256, 12, 12]             512\n",
      "           ResNet-39          [-1, 256, 12, 12]               0\n",
      "           Conv2d-40          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-41          [-1, 256, 12, 12]             512\n",
      "             ReLU-42          [-1, 256, 12, 12]               0\n",
      "           Conv2d-43          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-44          [-1, 256, 12, 12]             512\n",
      "           ResNet-45          [-1, 256, 12, 12]               0\n",
      "           Conv2d-46          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-47          [-1, 256, 12, 12]             512\n",
      "             ReLU-48          [-1, 256, 12, 12]               0\n",
      "           Conv2d-49          [-1, 256, 12, 12]         590,080\n",
      "      BatchNorm2d-50          [-1, 256, 12, 12]             512\n",
      "           ResNet-51          [-1, 256, 12, 12]               0\n",
      "        AvgPool2d-52            [-1, 256, 6, 6]               0\n",
      "           Conv2d-53            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-54            [-1, 256, 6, 6]             512\n",
      "             ReLU-55            [-1, 256, 6, 6]               0\n",
      "           Conv2d-56            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 6, 6]             512\n",
      "           ResNet-58            [-1, 256, 6, 6]               0\n",
      "           Conv2d-59            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-60            [-1, 256, 6, 6]             512\n",
      "             ReLU-61            [-1, 256, 6, 6]               0\n",
      "           Conv2d-62            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-63            [-1, 256, 6, 6]             512\n",
      "           ResNet-64            [-1, 256, 6, 6]               0\n",
      "           Conv2d-65            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-66            [-1, 256, 6, 6]             512\n",
      "             ReLU-67            [-1, 256, 6, 6]               0\n",
      "           Conv2d-68            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-69            [-1, 256, 6, 6]             512\n",
      "           ResNet-70            [-1, 256, 6, 6]               0\n",
      "           Conv2d-71            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-72            [-1, 256, 6, 6]             512\n",
      "             ReLU-73            [-1, 256, 6, 6]               0\n",
      "           Conv2d-74            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-75            [-1, 256, 6, 6]             512\n",
      "           ResNet-76            [-1, 256, 6, 6]               0\n",
      "           Conv2d-77            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-78            [-1, 256, 6, 6]             512\n",
      "             ReLU-79            [-1, 256, 6, 6]               0\n",
      "           Conv2d-80            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-81            [-1, 256, 6, 6]             512\n",
      "           ResNet-82            [-1, 256, 6, 6]               0\n",
      "           Conv2d-83            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-84            [-1, 256, 6, 6]             512\n",
      "             ReLU-85            [-1, 256, 6, 6]               0\n",
      "           Conv2d-86            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-87            [-1, 256, 6, 6]             512\n",
      "           ResNet-88            [-1, 256, 6, 6]               0\n",
      "           Conv2d-89            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-90            [-1, 256, 6, 6]             512\n",
      "             ReLU-91            [-1, 256, 6, 6]               0\n",
      "           Conv2d-92            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-93            [-1, 256, 6, 6]             512\n",
      "           ResNet-94            [-1, 256, 6, 6]               0\n",
      "           Conv2d-95            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-96            [-1, 256, 6, 6]             512\n",
      "             ReLU-97            [-1, 256, 6, 6]               0\n",
      "           Conv2d-98            [-1, 256, 6, 6]         590,080\n",
      "      BatchNorm2d-99            [-1, 256, 6, 6]             512\n",
      "          ResNet-100            [-1, 256, 6, 6]               0\n",
      "          Conv2d-101            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-102            [-1, 256, 6, 6]             512\n",
      "            ReLU-103            [-1, 256, 6, 6]               0\n",
      "          Conv2d-104            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-105            [-1, 256, 6, 6]             512\n",
      "          ResNet-106            [-1, 256, 6, 6]               0\n",
      "          Conv2d-107            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-108            [-1, 256, 6, 6]             512\n",
      "            ReLU-109            [-1, 256, 6, 6]               0\n",
      "          Conv2d-110            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-111            [-1, 256, 6, 6]             512\n",
      "          ResNet-112            [-1, 256, 6, 6]               0\n",
      "          Conv2d-113            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-114            [-1, 256, 6, 6]             512\n",
      "            ReLU-115            [-1, 256, 6, 6]               0\n",
      "          Conv2d-116            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-117            [-1, 256, 6, 6]             512\n",
      "          ResNet-118            [-1, 256, 6, 6]               0\n",
      "          Conv2d-119            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-120            [-1, 256, 6, 6]             512\n",
      "            ReLU-121            [-1, 256, 6, 6]               0\n",
      "          Conv2d-122            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-123            [-1, 256, 6, 6]             512\n",
      "          ResNet-124            [-1, 256, 6, 6]               0\n",
      "          Conv2d-125            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-126            [-1, 256, 6, 6]             512\n",
      "            ReLU-127            [-1, 256, 6, 6]               0\n",
      "          Conv2d-128            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-129            [-1, 256, 6, 6]             512\n",
      "          ResNet-130            [-1, 256, 6, 6]               0\n",
      "          Conv2d-131            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-132            [-1, 256, 6, 6]             512\n",
      "            ReLU-133            [-1, 256, 6, 6]               0\n",
      "          Conv2d-134            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-135            [-1, 256, 6, 6]             512\n",
      "          ResNet-136            [-1, 256, 6, 6]               0\n",
      "          Conv2d-137            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-138            [-1, 256, 6, 6]             512\n",
      "            ReLU-139            [-1, 256, 6, 6]               0\n",
      "          Conv2d-140            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-141            [-1, 256, 6, 6]             512\n",
      "          ResNet-142            [-1, 256, 6, 6]               0\n",
      "          Conv2d-143            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-144            [-1, 256, 6, 6]             512\n",
      "            ReLU-145            [-1, 256, 6, 6]               0\n",
      "          Conv2d-146            [-1, 256, 6, 6]         590,080\n",
      "     BatchNorm2d-147            [-1, 256, 6, 6]             512\n",
      "          ResNet-148            [-1, 256, 6, 6]               0\n",
      "          Conv2d-149              [-1, 1, 6, 6]             257\n",
      "     BatchNorm2d-150              [-1, 1, 6, 6]               2\n",
      "            ReLU-151              [-1, 1, 6, 6]               0\n",
      "         Flatten-152                   [-1, 36]               0\n",
      "          Linear-153                    [-1, 2]              74\n",
      "          Conv2d-154              [-1, 1, 6, 6]             257\n",
      "     BatchNorm2d-155              [-1, 1, 6, 6]               2\n",
      "            ReLU-156              [-1, 1, 6, 6]               0\n",
      "         Flatten-157                   [-1, 36]               0\n",
      "          Linear-158                    [-1, 6]             222\n",
      "            ReLU-159                    [-1, 6]               0\n",
      "          Linear-160                    [-1, 1]               7\n",
      "          Conv2d-161              [-1, 1, 6, 6]             257\n",
      "     BatchNorm2d-162              [-1, 1, 6, 6]               2\n",
      "            ReLU-163              [-1, 1, 6, 6]               0\n",
      "         Flatten-164                   [-1, 36]               0\n",
      "          Linear-165                    [-1, 6]             222\n",
      "            ReLU-166                    [-1, 6]               0\n",
      "          Linear-167                    [-1, 1]               7\n",
      "================================================================\n",
      "Total params: 27,021,469\n",
      "Trainable params: 27,021,469\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.50\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 103.08\n",
      "Estimated Total Size (MB): 170.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "m = MuNet(2,is_reference=True).cuda()\n",
    "summary(m,(128, 96, 96))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9640eeea7cea2ab399466f9f17548d33e58f55ecdddb9fb78ef9c1423e62776a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
