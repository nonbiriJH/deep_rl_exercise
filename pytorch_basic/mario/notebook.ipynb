{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym-super-mario-bros==7.3.0\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os, copy\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junhongchen/Documents/GitHub/deep_rl_exercise/pytorch_basic/venv/lib/python3.8/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3` with the environment ID `SuperMarioBros-1-1-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78b614eca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Super Mario environment\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
    "plt.imshow(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        #bilinear resize\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78b5200310>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
    "plt.imshow(next_state[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.net = self.net.to(device=\"cuda\")\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = exploration_rate_decay\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = save_every  # no. of experiences between saving Mario Net\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    Given a state, choose an epsilon-greedy action and update value of step.\n",
    "\n",
    "    Inputs:\n",
    "    state(LazyFrame): A single observation of the current state, dimension is (state_dim)\n",
    "    Outputs:\n",
    "    action_idx (int): An integer representing which action Mario will perform\n",
    "    \"\"\"\n",
    "        # EXPLORE\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # EXPLOIT\n",
    "        else:\n",
    "            state = state.__array__() #from lazy frame to array\n",
    "            if self.use_cuda:\n",
    "                state = torch.tensor(state).cuda()\n",
    "            else:\n",
    "                state = torch.tensor(state)\n",
    "            state = state.unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent's memory\n",
    "class Mario(Mario):  # subclassing for continuity\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Each time Mario performs an action, he stores the experience to his memory. \n",
    "        His experience includes the current state, action performed, reward from the action, the next state, and whether the game is done.\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (LazyFrame),\n",
    "        next_state (LazyFrame),\n",
    "        action (int),\n",
    "        reward (float),\n",
    "        done(bool))\n",
    "        \"\"\"\n",
    "        state = state.__array__()\n",
    "        next_state = next_state.__array__()\n",
    "\n",
    "        if self.use_cuda:\n",
    "            state = torch.tensor(state).cuda()\n",
    "            next_state = torch.tensor(next_state).cuda()\n",
    "            action = torch.tensor([action]).cuda()\n",
    "            reward = torch.tensor([reward]).cuda()\n",
    "            done = torch.tensor([done]).cuda()\n",
    "        else:\n",
    "            state = torch.tensor(state)\n",
    "            next_state = torch.tensor(next_state)\n",
    "            action = torch.tensor([action])\n",
    "            reward = torch.tensor([reward])\n",
    "            done = torch.tensor([done])\n",
    "\n",
    "        self.memory.append((state, next_state, action, reward, done,))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        # *batch: unpact batch to individual (s,s',a,r,d)\n",
    "        # zip(): create an iteracble on unpacked batch\n",
    "        # map(): apply torch.stack in each iterable\n",
    "        # torch.stack: Concatenates a sequence of tensors along a new dimension.\n",
    "        state, next_state, action, reward, done = map(torch.stack, zip(*batch))\n",
    "        # squeeze(): dimension 1 is removed\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DDQN: two ConvNets - online & target, that independently approximate the optimal action-value function.\n",
    "#Both share the same nn struc but seperate (w,b)\n",
    "#target does not back propagate to update (w,b). Periodically sync with online\n",
    "class MarioNet(nn.Module):\n",
    "    \"\"\"mini cnn structure\n",
    "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )\n",
    "\n",
    "        self.target = copy.deepcopy(self.online)\n",
    "\n",
    "        # Q_target parameters are frozen.\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        \n",
    "        current_state_Q = self.net(state, model=\"online\")#Q for (batch,action_space)\n",
    "        current_Q = current_state_Q[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        \n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad() #dont need to backpropagate on target (w,b)\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        #use online model to find a'\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        #use target model to find q(s',a')\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=learn_rate)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss() #mean reduction\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target) #loss between current and target TD\n",
    "        self.optimizer.zero_grad() #reset grad on each weight to 0, otherwise accumulate on batch\n",
    "        loss.backward() #compute loss grad wrt weights\n",
    "        #theta <- theta + lr * Delta(TD_target-q(s,a))\n",
    "        self.optimizer.step() #adjust weights by grad and learning rate\n",
    "        return loss.item() #report loss\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        #periodically copy online weights to target model\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoint\n",
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate), #exploration rate changing during training\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")\n",
    "    def load(self,load_path):\n",
    "        try:\n",
    "            self.net.load_state_dict(torch.load(load_path)['model'])\n",
    "            self.exploration_rate = torch.load(load_path)['exploration_rate']\n",
    "        except:\n",
    "            print(\n",
    "                f\"no weights are loaded as either {load_path} cannot be found or incompatible to current model.\")\n",
    "        else:\n",
    "            print(f\"weights are loaded successfuly! exploration_rate is {self.exploration_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate):\n",
    "        super().__init__(state_dim, action_dim, save_dir, exploration_rate_decay, save_every, learn_rate)\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory in batch\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate in batch\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target in batch\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_rewards\", \"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\"]:\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"))\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "\n",
      "weights are loaded successfuly! exploration_rate is 0.21224793265768857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/cgj1j5y91d591cjz0b83gx3r0000gn/T/ipykernel_99876/3067730520.py:35: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  done = torch.tensor([done])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Step 576 - Epsilon 0.2122173711520427 - Mean Reward 2302.0 - Mean Length 576.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 7.118 - Time 2022-03-13T01:35:12\n",
      "Episode 20 - Step 3807 - Epsilon 0.2120460217621031 - Mean Reward 901.095 - Mean Length 181.286 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 40.894 - Time 2022-03-13T01:35:53\n",
      "Episode 40 - Step 9145 - Epsilon 0.21176323504208022 - Mean Reward 970.024 - Mean Length 223.049 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 57.692 - Time 2022-03-13T01:36:51\n",
      "Episode 60 - Step 12088 - Epsilon 0.21160748752505176 - Mean Reward 899.82 - Mean Length 198.164 - Mean Loss 0.442 - Mean Q Value 9.267 - Time Delta 86.305 - Time 2022-03-13T01:38:17\n",
      "Episode 80 - Step 16906 - Epsilon 0.21135275971507198 - Mean Reward 915.21 - Mean Length 208.716 - Mean Loss 0.679 - Mean Q Value 17.577 - Time Delta 174.137 - Time 2022-03-13T01:41:11\n",
      "Episode 100 - Step 20634 - Epsilon 0.21115587068292016 - Mean Reward 893.02 - Mean Length 200.58 - Mean Loss 0.836 - Mean Q Value 22.777 - Time Delta 134.242 - Time 2022-03-13T01:43:25\n",
      "Episode 120 - Step 24734 - Epsilon 0.21093954677334184 - Mean Reward 900.57 - Mean Length 209.27 - Mean Loss 1.146 - Mean Q Value 31.296 - Time Delta 147.667 - Time 2022-03-13T01:45:53\n",
      "Episode 140 - Step 28547 - Epsilon 0.2107385644336563 - Mean Reward 859.2 - Mean Length 194.02 - Mean Loss 1.426 - Mean Q Value 39.82 - Time Delta 128.774 - Time 2022-03-13T01:48:02\n",
      "Episode 160 - Step 31179 - Epsilon 0.21059994405201893 - Mean Reward 829.6 - Mean Length 190.91 - Mean Loss 1.456 - Mean Q Value 42.756 - Time Delta 84.097 - Time 2022-03-13T01:49:26\n",
      "Episode 180 - Step 34479 - Epsilon 0.21042627072654052 - Mean Reward 772.95 - Mean Length 175.73 - Mean Loss 1.474 - Mean Q Value 42.682 - Time Delta 103.675 - Time 2022-03-13T01:51:10\n",
      "Episode 200 - Step 38028 - Epsilon 0.21023965279510726 - Mean Reward 755.98 - Mean Length 173.94 - Mean Loss 1.492 - Mean Q Value 42.603 - Time Delta 113.917 - Time 2022-03-13T01:53:04\n",
      "Episode 220 - Step 41721 - Epsilon 0.2100456385869758 - Mean Reward 755.61 - Mean Length 169.87 - Mean Loss 1.46 - Mean Q Value 42.609 - Time Delta 116.91 - Time 2022-03-13T01:55:01\n",
      "Episode 240 - Step 44980 - Epsilon 0.20987457357860054 - Mean Reward 749.01 - Mean Length 164.33 - Mean Loss 1.451 - Mean Q Value 42.727 - Time Delta 104.972 - Time 2022-03-13T01:56:45\n",
      "Episode 260 - Step 50176 - Epsilon 0.2096021234680863 - Mean Reward 796.83 - Mean Length 189.97 - Mean Loss 1.426 - Mean Q Value 42.565 - Time Delta 176.489 - Time 2022-03-13T01:59:42\n",
      "Episode 280 - Step 54199 - Epsilon 0.20939142208026232 - Mean Reward 817.65 - Mean Length 197.2 - Mean Loss 1.418 - Mean Q Value 42.326 - Time Delta 139.268 - Time 2022-03-13T02:02:01\n",
      "Episode 300 - Step 58986 - Epsilon 0.20914098275107176 - Mean Reward 805.43 - Mean Length 209.58 - Mean Loss 1.393 - Mean Q Value 42.06 - Time Delta 168.292 - Time 2022-03-13T02:04:50\n",
      "Episode 320 - Step 64371 - Epsilon 0.20885961610525172 - Mean Reward 811.26 - Mean Length 226.5 - Mean Loss 1.382 - Mean Q Value 41.618 - Time Delta 179.566 - Time 2022-03-13T02:07:49\n",
      "Episode 340 - Step 70142 - Epsilon 0.2085585011254847 - Mean Reward 823.99 - Mean Length 251.62 - Mean Loss 1.38 - Mean Q Value 40.892 - Time Delta 329.948 - Time 2022-03-13T02:13:19\n",
      "Episode 360 - Step 73598 - Epsilon 0.20837838437961184 - Mean Reward 827.73 - Mean Length 234.22 - Mean Loss 1.364 - Mean Q Value 40.327 - Time Delta 285.622 - Time 2022-03-13T02:18:05\n",
      "Episode 380 - Step 76852 - Epsilon 0.20820893747458824 - Mean Reward 823.39 - Mean Length 226.53 - Mean Loss 1.327 - Mean Q Value 39.988 - Time Delta 381.442 - Time 2022-03-13T02:24:26\n",
      "Episode 400 - Step 80013 - Epsilon 0.20804446533677903 - Mean Reward 823.03 - Mean Length 210.27 - Mean Loss 1.316 - Mean Q Value 39.788 - Time Delta 411.695 - Time 2022-03-13T02:31:18\n",
      "Episode 420 - Step 85781 - Epsilon 0.20774468137643 - Mean Reward 813.06 - Mean Length 214.1 - Mean Loss 1.307 - Mean Q Value 39.443 - Time Delta 459.802 - Time 2022-03-13T02:38:58\n",
      "Episode 440 - Step 91153 - Epsilon 0.20746586749987558 - Mean Reward 794.01 - Mean Length 210.11 - Mean Loss 1.285 - Mean Q Value 39.288 - Time Delta 239.584 - Time 2022-03-13T02:42:57\n",
      "Episode 460 - Step 93874 - Epsilon 0.20732478681636235 - Mean Reward 741.22 - Mean Length 202.76 - Mean Loss 1.282 - Mean Q Value 39.061 - Time Delta 113.625 - Time 2022-03-13T02:44:51\n",
      "Episode 480 - Step 97424 - Epsilon 0.20714086767123985 - Mean Reward 740.79 - Mean Length 205.72 - Mean Loss 1.278 - Mean Q Value 38.802 - Time Delta 151.482 - Time 2022-03-13T02:47:22\n",
      "Episode 500 - Step 100644 - Epsilon 0.2069741863501386 - Mean Reward 755.98 - Mean Length 206.31 - Mean Loss 1.264 - Mean Q Value 38.553 - Time Delta 169.018 - Time 2022-03-13T02:50:11\n",
      "Episode 520 - Step 104246 - Epsilon 0.20678788996455363 - Mean Reward 744.82 - Mean Length 184.65 - Mean Loss 1.283 - Mean Q Value 38.526 - Time Delta 153.599 - Time 2022-03-13T02:52:45\n",
      "Episode 540 - Step 108088 - Epsilon 0.20658936552802287 - Mean Reward 763.16 - Mean Length 169.35 - Mean Loss 1.29 - Mean Q Value 38.446 - Time Delta 172.329 - Time 2022-03-13T02:55:37\n",
      "Episode 560 - Step 111669 - Epsilon 0.2064044991385651 - Mean Reward 784.21 - Mean Length 177.95 - Mean Loss 1.301 - Mean Q Value 38.542 - Time Delta 231.171 - Time 2022-03-13T02:59:28\n",
      "Episode 580 - Step 118183 - Epsilon 0.20606864291484348 - Mean Reward 782.07 - Mean Length 207.59 - Mean Loss 1.289 - Mean Q Value 38.543 - Time Delta 818.765 - Time 2022-03-13T03:13:07\n",
      "Episode 600 - Step 122562 - Epsilon 0.20584317267908656 - Mean Reward 791.43 - Mean Length 219.18 - Mean Loss 1.295 - Mean Q Value 38.354 - Time Delta 207.021 - Time 2022-03-13T03:16:34\n",
      "Episode 620 - Step 125569 - Epsilon 0.20568848820397967 - Mean Reward 774.72 - Mean Length 213.23 - Mean Loss 1.278 - Mean Q Value 38.126 - Time Delta 143.308 - Time 2022-03-13T03:18:58\n",
      "Episode 640 - Step 129419 - Epsilon 0.20549060825432344 - Mean Reward 778.41 - Mean Length 213.31 - Mean Loss 1.282 - Mean Q Value 37.914 - Time Delta 223.954 - Time 2022-03-13T03:22:41\n",
      "Episode 660 - Step 132736 - Epsilon 0.2053202757799766 - Mean Reward 784.99 - Mean Length 210.67 - Mean Loss 1.27 - Mean Q Value 37.705 - Time Delta 152.039 - Time 2022-03-13T03:25:14\n",
      "Episode 680 - Step 136771 - Epsilon 0.20511326335532434 - Mean Reward 809.1 - Mean Length 185.88 - Mean Loss 1.301 - Mean Q Value 37.515 - Time Delta 191.952 - Time 2022-03-13T03:28:25\n",
      "Episode 700 - Step 141504 - Epsilon 0.20487070658705328 - Mean Reward 789.49 - Mean Length 189.42 - Mean Loss 1.289 - Mean Q Value 37.484 - Time Delta 215.272 - Time 2022-03-13T03:32:01\n",
      "Episode 720 - Step 145052 - Epsilon 0.20468906681672736 - Mean Reward 808.0 - Mean Length 194.83 - Mean Loss 1.285 - Mean Q Value 37.34 - Time Delta 158.896 - Time 2022-03-13T03:34:40\n",
      "Episode 740 - Step 147663 - Epsilon 0.20455549960938818 - Mean Reward 756.68 - Mean Length 182.44 - Mean Loss 1.283 - Mean Q Value 37.283 - Time Delta 116.314 - Time 2022-03-13T03:36:36\n",
      "Episode 760 - Step 152541 - Epsilon 0.20430619619007392 - Mean Reward 759.74 - Mean Length 198.05 - Mean Loss 1.278 - Mean Q Value 37.102 - Time Delta 219.722 - Time 2022-03-13T03:40:16\n",
      "Episode 780 - Step 156808 - Epsilon 0.20408836873240657 - Mean Reward 781.64 - Mean Length 200.37 - Mean Loss 1.265 - Mean Q Value 37.016 - Time Delta 191.914 - Time 2022-03-13T03:43:28\n",
      "Episode 800 - Step 160420 - Epsilon 0.2039041600951062 - Mean Reward 797.63 - Mean Length 189.16 - Mean Loss 1.277 - Mean Q Value 37.053 - Time Delta 163.592 - Time 2022-03-13T03:46:11\n",
      "Episode 820 - Step 164349 - Epsilon 0.20370397354151845 - Mean Reward 813.0 - Mean Length 192.97 - Mean Loss 1.301 - Mean Q Value 37.351 - Time Delta 176.116 - Time 2022-03-13T03:49:07\n",
      "Episode 840 - Step 167269 - Epsilon 0.20355532388595693 - Mean Reward 836.96 - Mean Length 196.06 - Mean Loss 1.305 - Mean Q Value 37.642 - Time Delta 130.153 - Time 2022-03-13T03:51:17\n",
      "Episode 860 - Step 171444 - Epsilon 0.20334297382953992 - Mean Reward 878.64 - Mean Length 189.03 - Mean Loss 1.306 - Mean Q Value 38.172 - Time Delta 184.489 - Time 2022-03-13T03:54:22\n",
      "Episode 880 - Step 174718 - Epsilon 0.20317660568009424 - Mean Reward 831.7 - Mean Length 179.1 - Mean Loss 1.316 - Mean Q Value 38.619 - Time Delta 145.177 - Time 2022-03-13T03:56:47\n",
      "Episode 900 - Step 179574 - Epsilon 0.20293009890983638 - Mean Reward 861.9 - Mean Length 191.54 - Mean Loss 1.311 - Mean Q Value 38.845 - Time Delta 214.667 - Time 2022-03-13T04:00:22\n",
      "Episode 920 - Step 183805 - Epsilon 0.20271556305352095 - Mean Reward 876.15 - Mean Length 194.56 - Mean Loss 1.308 - Mean Q Value 39.008 - Time Delta 191.929 - Time 2022-03-13T04:03:34\n",
      "Episode 940 - Step 187968 - Epsilon 0.20250469655357375 - Mean Reward 941.17 - Mean Length 206.99 - Mean Loss 1.329 - Mean Q Value 39.256 - Time Delta 190.238 - Time 2022-03-13T04:06:44\n",
      "Episode 960 - Step 191783 - Epsilon 0.20231164974890647 - Mean Reward 926.28 - Mean Length 203.39 - Mean Loss 1.358 - Mean Q Value 39.438 - Time Delta 174.207 - Time 2022-03-13T04:09:38\n",
      "Episode 980 - Step 195691 - Epsilon 0.20211408776712214 - Mean Reward 932.99 - Mean Length 209.73 - Mean Loss 1.374 - Mean Q Value 39.757 - Time Delta 173.011 - Time 2022-03-13T04:12:31\n",
      "Episode 1000 - Step 198779 - Epsilon 0.20195811588474138 - Mean Reward 891.43 - Mean Length 192.05 - Mean Loss 1.384 - Mean Q Value 40.171 - Time Delta 134.767 - Time 2022-03-13T04:14:46\n",
      "MarioNet saved to checkpoints/2022-03-13T01-35-05/mario_net_1.chkpt at step 200000\n",
      "Episode 1020 - Step 201527 - Epsilon 0.20181941828985056 - Mean Reward 836.29 - Mean Length 177.22 - Mean Loss 1.396 - Mean Q Value 40.545 - Time Delta 120.366 - Time 2022-03-13T04:16:46\n",
      "Episode 1040 - Step 204976 - Epsilon 0.2016454744769665 - Mean Reward 792.32 - Mean Length 170.08 - Mean Loss 1.409 - Mean Q Value 40.85 - Time Delta 152.922 - Time 2022-03-13T04:19:19\n",
      "Episode 1060 - Step 208189 - Epsilon 0.2014835677638213 - Mean Reward 766.53 - Mean Length 164.06 - Mean Loss 1.4 - Mean Q Value 41.024 - Time Delta 146.449 - Time 2022-03-13T04:21:46\n",
      "Episode 1080 - Step 212537 - Epsilon 0.20126467408853457 - Mean Reward 785.03 - Mean Length 168.46 - Mean Loss 1.41 - Mean Q Value 41.151 - Time Delta 202.814 - Time 2022-03-13T04:25:08\n",
      "Episode 1100 - Step 217242 - Epsilon 0.20102807566275918 - Mean Reward 823.81 - Mean Length 184.63 - Mean Loss 1.444 - Mean Q Value 41.278 - Time Delta 215.827 - Time 2022-03-13T04:28:44\n",
      "Episode 1120 - Step 222344 - Epsilon 0.20077182777701477 - Mean Reward 875.02 - Mean Length 208.17 - Mean Loss 1.457 - Mean Q Value 41.543 - Time Delta 229.954 - Time 2022-03-13T04:32:34\n",
      "Episode 1140 - Step 226614 - Epsilon 0.20055761817877268 - Mean Reward 887.33 - Mean Length 216.38 - Mean Loss 1.458 - Mean Q Value 41.694 - Time Delta 191.129 - Time 2022-03-13T04:35:45\n",
      "Episode 1160 - Step 231252 - Epsilon 0.20032520635820156 - Mean Reward 934.37 - Mean Length 230.63 - Mean Loss 1.492 - Mean Q Value 41.829 - Time Delta 208.377 - Time 2022-03-13T04:39:14\n",
      "Episode 1180 - Step 235949 - Epsilon 0.20009011251170433 - Mean Reward 937.53 - Mean Length 234.12 - Mean Loss 1.51 - Mean Q Value 41.802 - Time Delta 210.274 - Time 2022-03-13T04:42:44\n",
      "Episode 1200 - Step 241115 - Epsilon 0.19983186289966132 - Mean Reward 951.42 - Mean Length 238.73 - Mean Loss 1.514 - Mean Q Value 41.688 - Time Delta 240.491 - Time 2022-03-13T04:46:45\n",
      "Episode 1220 - Step 243806 - Epsilon 0.19969747120815165 - Mean Reward 904.75 - Mean Length 214.62 - Mean Loss 1.517 - Mean Q Value 41.575 - Time Delta 126.966 - Time 2022-03-13T04:48:52\n",
      "Episode 1240 - Step 247734 - Epsilon 0.19950146452193127 - Mean Reward 891.81 - Mean Length 211.2 - Mean Loss 1.512 - Mean Q Value 41.45 - Time Delta 178.484 - Time 2022-03-13T04:51:50\n",
      "Episode 1260 - Step 251516 - Epsilon 0.19931292500973186 - Mean Reward 848.75 - Mean Length 202.64 - Mean Loss 1.515 - Mean Q Value 41.335 - Time Delta 170.182 - Time 2022-03-13T04:54:40\n",
      "Episode 1280 - Step 255457 - Epsilon 0.19911664863233133 - Mean Reward 865.35 - Mean Length 195.08 - Mean Loss 1.514 - Mean Q Value 41.382 - Time Delta 176.263 - Time 2022-03-13T04:57:36\n",
      "Episode 1300 - Step 259053 - Epsilon 0.19893772318185998 - Mean Reward 838.36 - Mean Length 179.38 - Mean Loss 1.504 - Mean Q Value 41.609 - Time Delta 159.414 - Time 2022-03-13T05:00:16\n",
      "Episode 1320 - Step 262776 - Epsilon 0.19875264801556447 - Mean Reward 844.14 - Mean Length 189.7 - Mean Loss 1.508 - Mean Q Value 41.629 - Time Delta 166.881 - Time 2022-03-13T05:03:03\n",
      "Episode 1340 - Step 265741 - Epsilon 0.19860537718578763 - Mean Reward 802.93 - Mean Length 180.07 - Mean Loss 1.53 - Mean Q Value 41.687 - Time Delta 132.838 - Time 2022-03-13T05:05:16\n",
      "Episode 1360 - Step 268527 - Epsilon 0.19846709668504806 - Mean Reward 757.85 - Mean Length 170.11 - Mean Loss 1.511 - Mean Q Value 41.675 - Time Delta 125.629 - Time 2022-03-13T05:07:21\n",
      "Episode 1380 - Step 272057 - Epsilon 0.19829202671130305 - Mean Reward 711.94 - Mean Length 166.0 - Mean Loss 1.505 - Mean Q Value 41.628 - Time Delta 158.051 - Time 2022-03-13T05:09:59\n",
      "Episode 1400 - Step 279047 - Epsilon 0.19794581394280947 - Mean Reward 717.86 - Mean Length 199.94 - Mean Loss 1.51 - Mean Q Value 41.41 - Time Delta 310.665 - Time 2022-03-13T05:15:10\n",
      "Episode 1420 - Step 283240 - Epsilon 0.19773842593362204 - Mean Reward 736.79 - Mean Length 204.64 - Mean Loss 1.512 - Mean Q Value 41.149 - Time Delta 186.549 - Time 2022-03-13T05:18:16\n",
      "Episode 1440 - Step 286433 - Epsilon 0.19758064419838847 - Mean Reward 775.18 - Mean Length 206.92 - Mean Loss 1.513 - Mean Q Value 40.913 - Time Delta 141.463 - Time 2022-03-13T05:20:38\n",
      "Episode 1460 - Step 290240 - Epsilon 0.19739268625542586 - Mean Reward 822.86 - Mean Length 217.13 - Mean Loss 1.515 - Mean Q Value 40.763 - Time Delta 167.615 - Time 2022-03-13T05:23:26\n",
      "Episode 1480 - Step 296180 - Epsilon 0.19709977561965727 - Mean Reward 871.71 - Mean Length 241.23 - Mean Loss 1.489 - Mean Q Value 40.399 - Time Delta 262.287 - Time 2022-03-13T05:27:48\n",
      "Episode 1500 - Step 300039 - Epsilon 0.1969097152824406 - Mean Reward 851.39 - Mean Length 209.92 - Mean Loss 1.453 - Mean Q Value 39.99 - Time Delta 169.635 - Time 2022-03-13T05:30:37\n",
      "Episode 1520 - Step 303891 - Epsilon 0.19672018247759912 - Mean Reward 860.97 - Mean Length 206.51 - Mean Loss 1.42 - Mean Q Value 39.762 - Time Delta 174.117 - Time 2022-03-13T05:33:32\n",
      "Episode 1540 - Step 306917 - Epsilon 0.1965714199174716 - Mean Reward 847.83 - Mean Length 204.84 - Mean Loss 1.378 - Mean Q Value 39.469 - Time Delta 135.394 - Time 2022-03-13T05:35:47\n",
      "Episode 1560 - Step 310389 - Epsilon 0.19640086993304193 - Mean Reward 851.9 - Mean Length 201.49 - Mean Loss 1.348 - Mean Q Value 39.26 - Time Delta 155.077 - Time 2022-03-13T05:38:22\n",
      "Episode 1580 - Step 317151 - Epsilon 0.19606913469911633 - Mean Reward 828.65 - Mean Length 209.71 - Mean Loss 1.352 - Mean Q Value 39.118 - Time Delta 304.605 - Time 2022-03-13T05:43:27\n",
      "Episode 1600 - Step 321168 - Epsilon 0.195872331082523 - Mean Reward 836.96 - Mean Length 211.29 - Mean Loss 1.369 - Mean Q Value 38.962 - Time Delta 181.044 - Time 2022-03-13T05:46:28\n",
      "Episode 1620 - Step 327785 - Epsilon 0.19554857709716053 - Mean Reward 866.97 - Mean Length 238.94 - Mean Loss 1.372 - Mean Q Value 38.821 - Time Delta 298.722 - Time 2022-03-13T05:51:26\n",
      "Episode 1640 - Step 330734 - Epsilon 0.19540446202160855 - Mean Reward 858.53 - Mean Length 238.17 - Mean Loss 1.371 - Mean Q Value 38.673 - Time Delta 132.742 - Time 2022-03-13T05:53:39\n",
      "Episode 1660 - Step 334503 - Epsilon 0.1952204288604783 - Mean Reward 856.6 - Mean Length 241.14 - Mean Loss 1.377 - Mean Q Value 38.578 - Time Delta 170.391 - Time 2022-03-13T05:56:30\n",
      "Episode 1680 - Step 339256 - Epsilon 0.1949885959218957 - Mean Reward 846.25 - Mean Length 221.05 - Mean Loss 1.357 - Mean Q Value 38.531 - Time Delta 211.955 - Time 2022-03-13T06:00:02\n",
      "Episode 1700 - Step 342926 - Epsilon 0.1948097759089857 - Mean Reward 864.31 - Mean Length 217.58 - Mean Loss 1.336 - Mean Q Value 38.612 - Time Delta 164.764 - Time 2022-03-13T06:02:46\n",
      "Episode 1720 - Step 348600 - Epsilon 0.19453363410717836 - Mean Reward 875.77 - Mean Length 208.15 - Mean Loss 1.318 - Mean Q Value 38.596 - Time Delta 255.489 - Time 2022-03-13T06:07:02\n",
      "Episode 1740 - Step 353909 - Epsilon 0.19427561057776208 - Mean Reward 913.73 - Mean Length 231.75 - Mean Loss 1.313 - Mean Q Value 38.667 - Time Delta 238.265 - Time 2022-03-13T06:11:00\n",
      "Episode 1760 - Step 359467 - Epsilon 0.19400585204125095 - Mean Reward 939.1 - Mean Length 249.64 - Mean Loss 1.287 - Mean Q Value 38.45 - Time Delta 250.816 - Time 2022-03-13T06:15:11\n",
      "Episode 1780 - Step 367553 - Epsilon 0.19361406529419545 - Mean Reward 946.47 - Mean Length 282.97 - Mean Loss 1.282 - Mean Q Value 38.187 - Time Delta 359.855 - Time 2022-03-13T06:21:11\n",
      "Episode 1800 - Step 372206 - Epsilon 0.19338897464830276 - Mean Reward 952.6 - Mean Length 292.8 - Mean Loss 1.261 - Mean Q Value 37.673 - Time Delta 208.27 - Time 2022-03-13T06:24:39\n",
      "Episode 1820 - Step 377106 - Epsilon 0.19315221816768224 - Mean Reward 941.57 - Mean Length 285.06 - Mean Loss 1.25 - Mean Q Value 37.347 - Time Delta 220.122 - Time 2022-03-13T06:28:19\n",
      "Episode 1840 - Step 384256 - Epsilon 0.1928072669265599 - Mean Reward 971.48 - Mean Length 303.47 - Mean Loss 1.258 - Mean Q Value 37.094 - Time Delta 318.553 - Time 2022-03-13T06:33:38\n",
      "Episode 1860 - Step 390639 - Epsilon 0.1924998400453507 - Mean Reward 971.94 - Mean Length 311.72 - Mean Loss 1.281 - Mean Q Value 36.898 - Time Delta 281.826 - Time 2022-03-13T06:38:19\n",
      "Episode 1880 - Step 394305 - Epsilon 0.19232349474246002 - Mean Reward 959.53 - Mean Length 267.52 - Mean Loss 1.295 - Mean Q Value 36.595 - Time Delta 162.89 - Time 2022-03-13T06:41:02\n",
      "Episode 1900 - Step 397613 - Epsilon 0.19216450894210246 - Mean Reward 939.49 - Mean Length 254.07 - Mean Loss 1.317 - Mean Q Value 36.699 - Time Delta 147.039 - Time 2022-03-13T06:43:29\n",
      "MarioNet saved to checkpoints/2022-03-13T01-35-05/mario_net_2.chkpt at step 400000\n",
      "Episode 1920 - Step 401247 - Epsilon 0.1919900067435177 - Mean Reward 878.92 - Mean Length 241.41 - Mean Loss 1.331 - Mean Q Value 36.696 - Time Delta 160.84 - Time 2022-03-13T06:46:10\n",
      "Episode 1940 - Step 404655 - Epsilon 0.19182650090069087 - Mean Reward 823.15 - Mean Length 203.99 - Mean Loss 1.34 - Mean Q Value 36.549 - Time Delta 152.934 - Time 2022-03-13T06:48:43\n",
      "Episode 1960 - Step 409677 - Epsilon 0.19158581382162035 - Mean Reward 815.87 - Mean Length 190.38 - Mean Loss 1.347 - Mean Q Value 36.498 - Time Delta 225.444 - Time 2022-03-13T06:52:29\n",
      "Episode 1980 - Step 414576 - Epsilon 0.1913513126987354 - Mean Reward 846.65 - Mean Length 202.71 - Mean Loss 1.342 - Mean Q Value 36.5 - Time Delta 221.09 - Time 2022-03-13T06:56:10\n",
      "Episode 2000 - Step 419083 - Epsilon 0.19113582900111134 - Mean Reward 874.79 - Mean Length 214.7 - Mean Loss 1.339 - Mean Q Value 36.51 - Time Delta 204.267 - Time 2022-03-13T06:59:34\n",
      "Episode 2020 - Step 422740 - Epsilon 0.19096116290399534 - Mean Reward 933.54 - Mean Length 214.93 - Mean Loss 1.341 - Mean Q Value 36.612 - Time Delta 164.255 - Time 2022-03-13T07:02:18\n",
      "Episode 2040 - Step 426737 - Epsilon 0.19077044024377593 - Mean Reward 981.17 - Mean Length 220.82 - Mean Loss 1.319 - Mean Q Value 36.901 - Time Delta 180.334 - Time 2022-03-13T07:05:19\n",
      "Episode 2060 - Step 429999 - Epsilon 0.19061493034807492 - Mean Reward 973.18 - Mean Length 203.22 - Mean Loss 1.298 - Mean Q Value 37.275 - Time Delta 146.536 - Time 2022-03-13T07:07:45\n",
      "Episode 2080 - Step 436492 - Epsilon 0.1903057656174095 - Mean Reward 967.48 - Mean Length 219.16 - Mean Loss 1.304 - Mean Q Value 37.733 - Time Delta 288.629 - Time 2022-03-13T07:12:34\n",
      "Episode 2100 - Step 441365 - Epsilon 0.19007406675167834 - Mean Reward 954.23 - Mean Length 222.82 - Mean Loss 1.296 - Mean Q Value 37.975 - Time Delta 218.464 - Time 2022-03-13T07:16:12\n",
      "Episode 2120 - Step 446480 - Epsilon 0.18983116484692852 - Mean Reward 935.09 - Mean Length 237.4 - Mean Loss 1.271 - Mean Q Value 37.931 - Time Delta 226.371 - Time 2022-03-13T07:19:59\n",
      "Episode 2140 - Step 450094 - Epsilon 0.18965972982546866 - Mean Reward 900.6 - Mean Length 233.57 - Mean Loss 1.275 - Mean Q Value 37.751 - Time Delta 160.884 - Time 2022-03-13T07:22:39\n",
      "Episode 2160 - Step 454027 - Epsilon 0.18947333852243334 - Mean Reward 895.54 - Mean Length 240.28 - Mean Loss 1.288 - Mean Q Value 37.48 - Time Delta 176.024 - Time 2022-03-13T07:25:35\n",
      "Episode 2180 - Step 457828 - Epsilon 0.18929337697775228 - Mean Reward 911.71 - Mean Length 213.36 - Mean Loss 1.266 - Mean Q Value 37.431 - Time Delta 169.949 - Time 2022-03-13T07:28:25\n",
      "Episode 2200 - Step 461157 - Epsilon 0.18913590308297065 - Mean Reward 888.86 - Mean Length 197.92 - Mean Loss 1.279 - Mean Q Value 37.475 - Time Delta 148.731 - Time 2022-03-13T07:30:54\n",
      "Episode 2220 - Step 465388 - Epsilon 0.18893595032511998 - Mean Reward 879.63 - Mean Length 189.08 - Mean Loss 1.313 - Mean Q Value 37.974 - Time Delta 189.124 - Time 2022-03-13T07:34:03\n",
      "Episode 2240 - Step 468381 - Epsilon 0.1887946318599685 - Mean Reward 865.25 - Mean Length 182.87 - Mean Loss 1.318 - Mean Q Value 38.504 - Time Delta 134.507 - Time 2022-03-13T07:36:18\n",
      "Episode 2260 - Step 471380 - Epsilon 0.18865313611686949 - Mean Reward 852.51 - Mean Length 173.53 - Mean Loss 1.323 - Mean Q Value 39.217 - Time Delta 134.597 - Time 2022-03-13T07:38:32\n",
      "Episode 2280 - Step 474971 - Epsilon 0.1884838487429762 - Mean Reward 833.26 - Mean Length 171.43 - Mean Loss 1.326 - Mean Q Value 39.846 - Time Delta 151.247 - Time 2022-03-13T07:41:04\n",
      "Episode 2300 - Step 479359 - Epsilon 0.1882771953051799 - Mean Reward 840.75 - Mean Length 182.02 - Mean Loss 1.33 - Mean Q Value 40.383 - Time Delta 182.791 - Time 2022-03-13T07:44:06\n",
      "Episode 2320 - Step 483272 - Epsilon 0.18809310317457933 - Mean Reward 852.76 - Mean Length 178.84 - Mean Loss 1.331 - Mean Q Value 40.626 - Time Delta 162.312 - Time 2022-03-13T07:46:49\n",
      "Episode 2340 - Step 487099 - Epsilon 0.18791323113561495 - Mean Reward 910.18 - Mean Length 187.18 - Mean Loss 1.349 - Mean Q Value 41.139 - Time Delta 158.657 - Time 2022-03-13T07:49:27\n",
      "Episode 2360 - Step 490815 - Epsilon 0.18773874078537175 - Mean Reward 954.61 - Mean Length 194.35 - Mean Loss 1.345 - Mean Q Value 41.705 - Time Delta 153.114 - Time 2022-03-13T07:52:00\n",
      "Episode 2380 - Step 494979 - Epsilon 0.1875434064209469 - Mean Reward 959.68 - Mean Length 200.08 - Mean Loss 1.37 - Mean Q Value 42.257 - Time Delta 172.201 - Time 2022-03-13T07:54:53\n",
      "Episode 2400 - Step 499265 - Epsilon 0.18734256125784507 - Mean Reward 993.95 - Mean Length 199.06 - Mean Loss 1.382 - Mean Q Value 42.847 - Time Delta 176.13 - Time 2022-03-13T07:57:49\n",
      "Episode 2420 - Step 502835 - Epsilon 0.18717543259326833 - Mean Reward 976.73 - Mean Length 195.63 - Mean Loss 1.386 - Mean Q Value 43.441 - Time Delta 151.737 - Time 2022-03-13T08:00:21\n",
      "Episode 2440 - Step 506722 - Epsilon 0.18699363318998644 - Mean Reward 968.35 - Mean Length 196.23 - Mean Loss 1.382 - Mean Q Value 43.794 - Time Delta 164.366 - Time 2022-03-13T08:03:05\n",
      "Episode 2460 - Step 511408 - Epsilon 0.18677469838740662 - Mean Reward 969.75 - Mean Length 205.93 - Mean Loss 1.386 - Mean Q Value 43.94 - Time Delta 199.858 - Time 2022-03-13T08:06:25\n",
      "Episode 2480 - Step 514966 - Epsilon 0.18660863613954395 - Mean Reward 966.66 - Mean Length 199.87 - Mean Loss 1.397 - Mean Q Value 44.216 - Time Delta 156.576 - Time 2022-03-13T08:09:01\n",
      "Episode 2500 - Step 518906 - Epsilon 0.18642491710643389 - Mean Reward 951.42 - Mean Length 196.41 - Mean Loss 1.382 - Mean Q Value 44.552 - Time Delta 177.471 - Time 2022-03-13T08:11:59\n",
      "Episode 2520 - Step 522719 - Epsilon 0.18624729220589323 - Mean Reward 983.08 - Mean Length 198.84 - Mean Loss 1.387 - Mean Q Value 44.851 - Time Delta 175.475 - Time 2022-03-13T08:14:54\n",
      "Episode 2540 - Step 526634 - Epsilon 0.18606509182470302 - Mean Reward 928.48 - Mean Length 199.12 - Mean Loss 1.386 - Mean Q Value 45.036 - Time Delta 175.031 - Time 2022-03-13T08:17:49\n",
      "Episode 2560 - Step 530437 - Epsilon 0.18588827448438605 - Mean Reward 923.97 - Mean Length 190.29 - Mean Loss 1.387 - Mean Q Value 45.256 - Time Delta 169.252 - Time 2022-03-13T08:20:39\n",
      "Episode 2580 - Step 535248 - Epsilon 0.18566483173410814 - Mean Reward 930.94 - Mean Length 202.82 - Mean Loss 1.406 - Mean Q Value 45.267 - Time Delta 217.042 - Time 2022-03-13T08:24:16\n",
      "Episode 2600 - Step 539259 - Epsilon 0.18547874961331495 - Mean Reward 918.04 - Mean Length 203.53 - Mean Loss 1.446 - Mean Q Value 45.317 - Time Delta 181.361 - Time 2022-03-13T08:27:17\n",
      "Episode 2620 - Step 544356 - Epsilon 0.18524255380527682 - Mean Reward 946.67 - Mean Length 216.37 - Mean Loss 1.463 - Mean Q Value 45.49 - Time Delta 229.567 - Time 2022-03-13T08:31:07\n",
      "Episode 2640 - Step 547912 - Epsilon 0.1850779463332072 - Mean Reward 948.13 - Mean Length 212.78 - Mean Loss 1.465 - Mean Q Value 45.778 - Time Delta 161.591 - Time 2022-03-13T08:33:48\n",
      "Episode 2660 - Step 551655 - Epsilon 0.18490484062772722 - Mean Reward 939.05 - Mean Length 212.18 - Mean Loss 1.475 - Mean Q Value 46.077 - Time Delta 169.963 - Time 2022-03-13T08:36:38\n",
      "Episode 2680 - Step 556417 - Epsilon 0.18468484236737634 - Mean Reward 990.66 - Mean Length 211.69 - Mean Loss 1.452 - Mean Q Value 46.459 - Time Delta 214.498 - Time 2022-03-13T08:40:13\n",
      "Episode 2700 - Step 559975 - Epsilon 0.18452063822016304 - Mean Reward 1000.88 - Mean Length 207.16 - Mean Loss 1.43 - Mean Q Value 46.789 - Time Delta 157.922 - Time 2022-03-13T08:42:51\n",
      "Episode 2720 - Step 563463 - Epsilon 0.18435980633640145 - Mean Reward 958.77 - Mean Length 191.07 - Mean Loss 1.43 - Mean Q Value 46.976 - Time Delta 158.867 - Time 2022-03-13T08:45:29\n",
      "Episode 2740 - Step 567438 - Epsilon 0.1841766897570599 - Mean Reward 976.18 - Mean Length 195.26 - Mean Loss 1.428 - Mean Q Value 47.123 - Time Delta 180.345 - Time 2022-03-13T08:48:30\n",
      "Episode 2760 - Step 571427 - Epsilon 0.18399311108235794 - Mean Reward 974.43 - Mean Length 197.72 - Mean Loss 1.455 - Mean Q Value 47.24 - Time Delta 179.578 - Time 2022-03-13T08:51:29\n",
      "Episode 2780 - Step 575156 - Epsilon 0.1838216634115595 - Mean Reward 916.3 - Mean Length 187.39 - Mean Loss 1.48 - Mean Q Value 47.341 - Time Delta 167.74 - Time 2022-03-13T08:54:17\n",
      "Episode 2800 - Step 579654 - Epsilon 0.18361507210293368 - Mean Reward 897.49 - Mean Length 196.79 - Mean Loss 1.474 - Mean Q Value 47.29 - Time Delta 200.983 - Time 2022-03-13T08:57:38\n",
      "Episode 2820 - Step 582963 - Epsilon 0.18346323932602737 - Mean Reward 878.17 - Mean Length 195.0 - Mean Loss 1.471 - Mean Q Value 47.367 - Time Delta 147.648 - Time 2022-03-13T09:00:06\n",
      "Episode 2840 - Step 586892 - Epsilon 0.18328312101174898 - Mean Reward 890.79 - Mean Length 194.54 - Mean Loss 1.469 - Mean Q Value 47.322 - Time Delta 176.196 - Time 2022-03-13T09:03:02\n",
      "Episode 2860 - Step 590156 - Epsilon 0.18313362296979158 - Mean Reward 853.3 - Mean Length 187.29 - Mean Loss 1.44 - Mean Q Value 47.227 - Time Delta 146.707 - Time 2022-03-13T09:05:29\n",
      "Episode 2880 - Step 594361 - Epsilon 0.1829412048820436 - Mean Reward 846.75 - Mean Length 192.05 - Mean Loss 1.427 - Mean Q Value 47.007 - Time Delta 188.396 - Time 2022-03-13T09:08:37\n",
      "Episode 2900 - Step 598266 - Epsilon 0.18276269565743156 - Mean Reward 862.52 - Mean Length 186.12 - Mean Loss 1.435 - Mean Q Value 46.938 - Time Delta 173.687 - Time 2022-03-13T09:11:31\n",
      "MarioNet saved to checkpoints/2022-03-13T01-35-05/mario_net_3.chkpt at step 600000\n",
      "Episode 2920 - Step 602583 - Epsilon 0.18256555539442304 - Mean Reward 898.35 - Mean Length 196.2 - Mean Loss 1.426 - Mean Q Value 46.766 - Time Delta 183.998 - Time 2022-03-13T09:14:35\n",
      "Episode 2940 - Step 606569 - Epsilon 0.18238371941054424 - Mean Reward 918.83 - Mean Length 196.77 - Mean Loss 1.44 - Mean Q Value 46.714 - Time Delta 165.872 - Time 2022-03-13T09:17:21\n",
      "Episode 2960 - Step 609920 - Epsilon 0.18223099141336818 - Mean Reward 950.88 - Mean Length 197.64 - Mean Loss 1.434 - Mean Q Value 46.673 - Time Delta 147.279 - Time 2022-03-13T09:19:48\n",
      "Episode 2980 - Step 613094 - Epsilon 0.1820864484585953 - Mean Reward 935.89 - Mean Length 187.33 - Mean Loss 1.427 - Mean Q Value 46.703 - Time Delta 140.966 - Time 2022-03-13T09:22:09\n",
      "Episode 3000 - Step 617428 - Epsilon 0.1818892646106545 - Mean Reward 938.61 - Mean Length 191.62 - Mean Loss 1.428 - Mean Q Value 46.662 - Time Delta 195.117 - Time 2022-03-13T09:25:24\n",
      "Episode 3020 - Step 622216 - Epsilon 0.18167167338801318 - Mean Reward 975.31 - Mean Length 196.33 - Mean Loss 1.422 - Mean Q Value 46.633 - Time Delta 215.164 - Time 2022-03-13T09:28:59\n",
      "Episode 3040 - Step 625202 - Epsilon 0.18153610607366036 - Mean Reward 935.91 - Mean Length 186.33 - Mean Loss 1.416 - Mean Q Value 46.576 - Time Delta 136.635 - Time 2022-03-13T09:31:16\n",
      "Episode 3060 - Step 628306 - Epsilon 0.18139528868193952 - Mean Reward 933.14 - Mean Length 183.86 - Mean Loss 1.415 - Mean Q Value 46.664 - Time Delta 139.632 - Time 2022-03-13T09:33:35\n",
      "Episode 3080 - Step 632634 - Epsilon 0.18119912509867406 - Mean Reward 958.39 - Mean Length 195.4 - Mean Loss 1.411 - Mean Q Value 46.794 - Time Delta 194.767 - Time 2022-03-13T09:36:50\n",
      "Episode 3100 - Step 635412 - Epsilon 0.18107332597935102 - Mean Reward 918.29 - Mean Length 179.84 - Mean Loss 1.402 - Mean Q Value 47.058 - Time Delta 126.831 - Time 2022-03-13T09:38:57\n",
      "Episode 3120 - Step 639494 - Epsilon 0.18088863488173818 - Mean Reward 880.23 - Mean Length 172.78 - Mean Loss 1.403 - Mean Q Value 47.339 - Time Delta 182.076 - Time 2022-03-13T09:41:59\n",
      "Episode 3140 - Step 643287 - Epsilon 0.18071718851211216 - Mean Reward 909.84 - Mean Length 180.85 - Mean Loss 1.401 - Mean Q Value 47.593 - Time Delta 170.092 - Time 2022-03-13T09:44:49\n",
      "Episode 3160 - Step 647088 - Epsilon 0.18054554354797875 - Mean Reward 928.86 - Mean Length 187.82 - Mean Loss 1.403 - Mean Q Value 47.899 - Time Delta 169.17 - Time 2022-03-13T09:47:38\n",
      "Episode 3180 - Step 650809 - Epsilon 0.18037766912978004 - Mean Reward 933.75 - Mean Length 181.75 - Mean Loss 1.416 - Mean Q Value 48.168 - Time Delta 165.662 - Time 2022-03-13T09:50:24\n",
      "Episode 3200 - Step 653879 - Epsilon 0.18023928236412035 - Mean Reward 945.35 - Mean Length 184.67 - Mean Loss 1.439 - Mean Q Value 48.316 - Time Delta 137.934 - Time 2022-03-13T09:52:42\n",
      "Episode 3220 - Step 658538 - Epsilon 0.18002947084643317 - Mean Reward 936.46 - Mean Length 190.44 - Mean Loss 1.461 - Mean Q Value 48.476 - Time Delta 207.905 - Time 2022-03-13T09:56:10\n",
      "Episode 3240 - Step 662447 - Epsilon 0.1798536229617103 - Mean Reward 953.44 - Mean Length 191.6 - Mean Loss 1.492 - Mean Q Value 48.568 - Time Delta 174.514 - Time 2022-03-13T09:59:04\n",
      "Episode 3260 - Step 666614 - Epsilon 0.17966635798513628 - Mean Reward 982.84 - Mean Length 195.26 - Mean Loss 1.519 - Mean Q Value 48.568 - Time Delta 186.425 - Time 2022-03-13T10:02:11\n",
      "Episode 3280 - Step 671275 - Epsilon 0.17945712366413222 - Mean Reward 972.52 - Mean Length 204.66 - Mean Loss 1.535 - Mean Q Value 48.518 - Time Delta 208.171 - Time 2022-03-13T10:05:39\n",
      "Episode 3300 - Step 674549 - Epsilon 0.17931029808660334 - Mean Reward 971.5 - Mean Length 206.7 - Mean Loss 1.546 - Mean Q Value 48.44 - Time Delta 146.629 - Time 2022-03-13T10:08:06\n",
      "Episode 3320 - Step 678369 - Epsilon 0.17913913847223634 - Mean Reward 957.63 - Mean Length 198.31 - Mean Loss 1.559 - Mean Q Value 48.298 - Time Delta 170.427 - Time 2022-03-13T10:10:56\n",
      "Episode 3340 - Step 682545 - Epsilon 0.1789522147794243 - Mean Reward 957.86 - Mean Length 200.98 - Mean Loss 1.572 - Mean Q Value 48.384 - Time Delta 184.13 - Time 2022-03-13T10:14:00\n",
      "Episode 3360 - Step 687054 - Epsilon 0.17875060452401384 - Mean Reward 952.16 - Mean Length 204.4 - Mean Loss 1.571 - Mean Q Value 48.412 - Time Delta 209.778 - Time 2022-03-13T10:17:30\n",
      "Episode 3380 - Step 690568 - Epsilon 0.17859364105459516 - Mean Reward 967.17 - Mean Length 192.93 - Mean Loss 1.549 - Mean Q Value 48.542 - Time Delta 159.832 - Time 2022-03-13T10:20:10\n",
      "Episode 3400 - Step 693765 - Epsilon 0.17845095709679942 - Mean Reward 967.33 - Mean Length 192.16 - Mean Loss 1.553 - Mean Q Value 48.848 - Time Delta 149.057 - Time 2022-03-13T10:22:39\n",
      "Episode 3420 - Step 696881 - Epsilon 0.1783119979154602 - Mean Reward 937.43 - Mean Length 185.12 - Mean Loss 1.559 - Mean Q Value 49.171 - Time Delta 143.396 - Time 2022-03-13T10:25:02\n",
      "Episode 3440 - Step 700774 - Epsilon 0.17813854016435304 - Mean Reward 936.32 - Mean Length 182.29 - Mean Loss 1.544 - Mean Q Value 49.338 - Time Delta 175.655 - Time 2022-03-13T10:27:58\n",
      "Episode 3460 - Step 704244 - Epsilon 0.1779840719716967 - Mean Reward 911.17 - Mean Length 171.9 - Mean Loss 1.554 - Mean Q Value 49.59 - Time Delta 156.392 - Time 2022-03-13T10:30:34\n",
      "Episode 3480 - Step 707425 - Epsilon 0.177842586386418 - Mean Reward 891.11 - Mean Length 168.57 - Mean Loss 1.58 - Mean Q Value 49.844 - Time Delta 142.572 - Time 2022-03-13T10:32:57\n",
      "Episode 3500 - Step 710163 - Epsilon 0.17772089477451367 - Mean Reward 870.66 - Mean Length 163.98 - Mean Loss 1.587 - Mean Q Value 49.908 - Time Delta 127.242 - Time 2022-03-13T10:35:04\n",
      "Episode 3520 - Step 713493 - Epsilon 0.17757300367931728 - Mean Reward 903.11 - Mean Length 166.12 - Mean Loss 1.582 - Mean Q Value 50.084 - Time Delta 154.132 - Time 2022-03-13T10:37:38\n",
      "Episode 3540 - Step 717458 - Epsilon 0.17739707162813254 - Mean Reward 880.84 - Mean Length 166.84 - Mean Loss 1.583 - Mean Q Value 50.292 - Time Delta 187.796 - Time 2022-03-13T10:40:46\n",
      "Episode 3560 - Step 721480 - Epsilon 0.17721878849716535 - Mean Reward 916.63 - Mean Length 172.36 - Mean Loss 1.603 - Mean Q Value 50.419 - Time Delta 186.295 - Time 2022-03-13T10:43:52\n",
      "Episode 3580 - Step 725097 - Epsilon 0.17705861081887028 - Mean Reward 936.34 - Mean Length 176.72 - Mean Loss 1.614 - Mean Q Value 50.549 - Time Delta 169.971 - Time 2022-03-13T10:46:42\n",
      "Episode 3600 - Step 728150 - Epsilon 0.17692352237694234 - Mean Reward 969.0 - Mean Length 179.87 - Mean Loss 1.62 - Mean Q Value 50.787 - Time Delta 140.691 - Time 2022-03-13T10:49:03\n",
      "Episode 3620 - Step 731049 - Epsilon 0.17679534349249315 - Mean Reward 941.5 - Mean Length 175.56 - Mean Loss 1.655 - Mean Q Value 50.839 - Time Delta 136.214 - Time 2022-03-13T10:51:19\n",
      "Episode 3640 - Step 734577 - Epsilon 0.17663947872649452 - Mean Reward 939.38 - Mean Length 171.19 - Mean Loss 1.688 - Mean Q Value 50.946 - Time Delta 166.687 - Time 2022-03-13T10:54:06\n",
      "Episode 3660 - Step 738602 - Epsilon 0.1764618246260037 - Mean Reward 915.21 - Mean Length 171.22 - Mean Loss 1.715 - Mean Q Value 51.107 - Time Delta 186.564 - Time 2022-03-13T10:57:12\n",
      "Episode 3680 - Step 742222 - Epsilon 0.17630219889627874 - Mean Reward 906.06 - Mean Length 171.25 - Mean Loss 1.741 - Mean Q Value 51.148 - Time Delta 168.1 - Time 2022-03-13T11:00:00\n",
      "Episode 3700 - Step 746581 - Epsilon 0.17611017819728317 - Mean Reward 936.55 - Mean Length 184.31 - Mean Loss 1.751 - Mean Q Value 51.156 - Time Delta 211.881 - Time 2022-03-13T11:03:32\n",
      "Episode 3720 - Step 749978 - Epsilon 0.17596068009935564 - Mean Reward 959.83 - Mean Length 189.29 - Mean Loss 1.725 - Mean Q Value 51.237 - Time Delta 164.736 - Time 2022-03-13T11:06:17\n",
      "Episode 3740 - Step 753492 - Epsilon 0.1758061665025871 - Mean Reward 967.29 - Mean Length 189.15 - Mean Loss 1.743 - Mean Q Value 51.311 - Time Delta 167.58 - Time 2022-03-13T11:09:05\n",
      "Episode 3760 - Step 757422 - Epsilon 0.17563352174801664 - Mean Reward 950.15 - Mean Length 188.2 - Mean Loss 1.713 - Mean Q Value 51.283 - Time Delta 186.784 - Time 2022-03-13T11:12:11\n",
      "Episode 3780 - Step 761459 - Epsilon 0.1754563530128333 - Mean Reward 983.76 - Mean Length 192.37 - Mean Loss 1.714 - Mean Q Value 51.5 - Time Delta 186.16 - Time 2022-03-13T11:15:18\n",
      "Episode 3800 - Step 764341 - Epsilon 0.17532998222521687 - Mean Reward 920.97 - Mean Length 177.6 - Mean Loss 1.741 - Mean Q Value 51.66 - Time Delta 133.814 - Time 2022-03-13T11:17:31\n",
      "Episode 3820 - Step 766393 - Epsilon 0.17524006099984898 - Mean Reward 846.96 - Mean Length 164.15 - Mean Loss 1.755 - Mean Q Value 51.775 - Time Delta 95.465 - Time 2022-03-13T11:19:07\n",
      "Episode 3840 - Step 769166 - Epsilon 0.17511861791243688 - Mean Reward 800.97 - Mean Length 156.74 - Mean Loss 1.731 - Mean Q Value 51.895 - Time Delta 129.209 - Time 2022-03-13T11:21:16\n",
      "Episode 3860 - Step 772482 - Epsilon 0.17497350471775747 - Mean Reward 786.58 - Mean Length 150.6 - Mean Loss 1.777 - Mean Q Value 52.092 - Time Delta 151.169 - Time 2022-03-13T11:23:47\n",
      "Episode 3880 - Step 775758 - Epsilon 0.17483026006616068 - Mean Reward 741.44 - Mean Length 142.99 - Mean Loss 1.768 - Mean Q Value 52.133 - Time Delta 151.106 - Time 2022-03-13T11:26:18\n",
      "Episode 3900 - Step 779251 - Epsilon 0.174677656162838 - Mean Reward 752.36 - Mean Length 149.1 - Mean Loss 1.741 - Mean Q Value 52.222 - Time Delta 161.262 - Time 2022-03-13T11:29:00\n",
      "Episode 3920 - Step 783267 - Epsilon 0.17450236778360448 - Mean Reward 844.98 - Mean Length 168.74 - Mean Loss 1.764 - Mean Q Value 52.347 - Time Delta 188.127 - Time 2022-03-13T11:32:08\n",
      "Episode 3940 - Step 787111 - Epsilon 0.17433475153969444 - Mean Reward 881.98 - Mean Length 179.45 - Mean Loss 1.781 - Mean Q Value 52.394 - Time Delta 175.743 - Time 2022-03-13T11:35:03\n",
      "Episode 3960 - Step 791921 - Epsilon 0.17412523996882778 - Mean Reward 938.58 - Mean Length 194.39 - Mean Loss 1.758 - Mean Q Value 52.32 - Time Delta 221.941 - Time 2022-03-13T11:38:45\n",
      "Episode 3980 - Step 795179 - Epsilon 0.1739834726856954 - Mean Reward 919.58 - Mean Length 194.21 - Mean Loss 1.757 - Mean Q Value 52.22 - Time Delta 148.299 - Time 2022-03-13T11:41:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir,exploration_rate_decay=0.99999975,save_every=2e5,learn_rate=0.00025)\n",
    "mario.load(\"/Users/junhongchen/Documents/GitHub/deep_rl_exercise/pytorch_basic/mario/checkpoints/2022-03-12T00-31-11/mario_net_4.chkpt\")\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 4000\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "153395977a4cf62fa0ab322e6c24bf351a1d4ed6f12edf1a6f663ca02414a93d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
